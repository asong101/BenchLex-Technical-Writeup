Large datasets are everywhere, and need to be indexed in order to allow for quickly accessing data. In indexing for databases, traditional methods of indexing keys and payloads are not state-of-the-art anymore. Traditional Indexing can quickly locate data, but the performance of the data structure depends on how ordered the data is. B+Trees offer a hierarchical data structure optimized for range queries, and hash indexes are ideal for key-value lookups but are inefficient when it comes to range queries. However, both do not leverage the distribution of the data, and show a decline in performance when data is not organized. In other words, traditional indexes offer robust performance numbers, but do not inherently optimize for the distribution of the data.

The recent introduction of learned indexes has established a new method of organizing data that utilizes novel learning techniques, in which the computing time and data allocation has significantly been reduced. Learned indexes (Kraska et al., 2018) utilizes basic machine learning to reduce time and memory consumption, and dynamically adapts to different patterns to achieve faster lookup times, offering a supposed improvement with different distributions of data. More specifically, a learned index treats indexing as a regression problem, where machine learning models approximate the CDF (Cumulative Distribution Function) of keys. This narrows the lookup time from a complexity of O(log(n)) when traversing a tree, to a complexity of O(1). Another benefit of learned indexes is that the memory requirement of the index is more efficient, requiring less parameters than the B+Tree. One small fallback of the learned index is that it is inefficient for dynamic datasets, where updates and deletions must also be factored in.

The development of ALEX: An Adaptable Learned Index (Ding et al., 2020) takes this one step further by allowing for updates on the data set to restructure the data structure. Furthermore, the development of ALEX: An Adaptable Learned Index takes this one step further by allowing for updates on the data set. It introduces gapped arrays to absorb insertions with minimal reshuffling, implements exponential search rather than traditional binary search, and it supports dynamic expansion by splitting nodes when model errors increase. ALEX is generally modeled after a B+Tree, with specific bulk pre-loading methods and the ability to store a combination of reads, writes, or mixed workloads. 

With the Boston University Data-intensive Systems and Computing lab, I performed research under Professor Manos Athanassoulis to benchmark the ability of ALEX to respond to different levels of sortedness. I took on the task of recreating ALEX. For our benchmark to have significance, we would have to simulate ALEX’s performance on different datasets, namely those built by a program named BoDs, built in the lab I was researching in. BoDs varies the dataset “sortedness” using the (K, L) metric: K represents the number of out-of-place elements, and L represents the maximum displacement of misplaced elements. Some examples of the datasets BoDs generates are Fully sorted (K = 0, L = 0), Near-sorted (low K, low L), Partially scrambled (high K, low L), and Fully scrambled (high K, high L). 

I adjusted the C++ code in ALEX’s machine learning program that interacts with a BoDs-generated dataset, and we conducted different tests that experimented with inserts, bulk loading, and different data set sizes. I adjusted the C++ code in ALEX’s machine learning program that interacts with a BoDs-generated dataset, and we conducted different tests that experimented with inserts, bulk loading, and different data set sizes. By incrementally adjusting the sortedness of each dataset, ALEX could respond to each respective dataset. Our results generally surprised us, showing high performance with very randomized and unsorted data, and gradually slowing down as the data set was closer and closer to being fully sorted. Numerically, we saw a general increase of 0.8 to 1.8 inserts/sec from (K = 10 to 50, L = 10 to 100) to (K = 100, L = 70). 

I analyzed the code of ALEX itself and identified key points on how ALEX responds individually to the dataset. I focused on probabilistic data analysis, and learned how ALEX groups similar forms of data together. ALEX dynamically groups similar data points into nodes, so fully scrambled data teaches the model a more generalized function, which results in less mispredictions. However, datasets that are near-sorted—slightly scrambled with small K and L values—cause localized model errors, which can lead to costly corrections. These observations led me to a crucial realization: if the data is all uniformly scrambled, the machine learning (ML) model would have a better time correctly finding a key after learning the dataset. This can be generalized to all ML: when training a fruit identification ML model, we must provide a variety of different fruit pictures, instead of just oranges—in short, ML thrives on randomization. My discovery has since allowed for further inquiry: How can we leverage this concept for real-world datasets?
